{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN trained on a custom dataset for image classification\n",
    "\n",
    "In this notebook we are going to train an image classifier from scratch in PyTorch.\n",
    "\n",
    "Before you proceed with this notebook, you need to collect the data for the classes you wish to create. To do so, you can follow any of the approaches presented in notebook ``04``.\n",
    "\n",
    "Your data, should then exist in a folder with the path: \n",
    "\n",
    "``./data/my_image_dataset/``\n",
    "\n",
    "Now you can proceed with the notebook. The following code has been adapted from notebook developed by [Terence Broad](https://github.com/terrybroad/CCI-AI-4-Media-23-24/blob/main/Week-3-CNNs-and-image-classification/train-image-classifier-from-scratch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sklearn is not installed, execute the following command when in the correct conda env\n",
    "#!conda install -c conda-forge scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.3\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "momentum = 0.9\n",
    "\n",
    "learn_rate = 0.001\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "num_classes = 3 # change if you are working with a different number of classes\n",
    "\n",
    "data_path = './data/my_image_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image transformations for the train dataset\n",
    "\n",
    "Could you augment your training data by adding more transformations to them?\n",
    "\n",
    "You could randomly change their brightness, contrast, saturation, and hue.\n",
    "\n",
    "You could flip them horizontally or vertically with a 0.5 probability.\n",
    "\n",
    "You could randomly rotate them.\n",
    "\n",
    "Look in [here](https://pytorch.org/vision/stable/transforms.html) and [here](https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py) for references and examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(size=(64, 64), antialias=True),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image transformations for the validation dataset\n",
    "\n",
    "Do you need to also add the above transformations to your validation set? Or are the existing ones enough? You need to consider what the purpose of each dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose(\n",
    "    [   \n",
    "        torchvision.transforms.Resize(64, antialias=True),\n",
    "        torchvision.transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create our train and test datasets\n",
    "\n",
    "Here we create our train and validation datasets by splitting the full input dataset into two subsets, with a ratio that was defined with the val_size at the beginning of the notebook. A 70-30 split is quite common.\n",
    "\n",
    "By setting a `random_state`, we are performing the split randomly but in a deterministic way, i.e. we will always get the same random train_test_split as long as we use the same random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation datasets with seperate transforms\n",
    "train_dataset = ImageFolder(data_path, transform=train_transform)\n",
    "val_dataset = ImageFolder(data_path, transform=val_transform)\n",
    "\n",
    "# get length of the full dataset before split, and save it in idx\n",
    "num_train = len(train_dataset)\n",
    "\n",
    "# create an array of idx numbers for each element of the full dataset\n",
    "idx = list(range(num_train))\n",
    "#print(num_train, idx)\n",
    "\n",
    "# perform train / val split for data points\n",
    "train_indices, val_indices = train_test_split(idx, test_size=val_size, random_state=42)\n",
    "\n",
    "# override datasets to only be samples for each split\n",
    "train_dataset = Subset(train_dataset, train_indices)\n",
    "val_dataset = Subset(val_dataset, val_indices)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot sample images from the two datasets\n",
    "\n",
    "In the next two cells we are plotting a sample of images from each dataset. See how the data augmentation transforms affect the images of the training set, compared to the images in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch of training images\n",
    "sample_batch = next(iter(train_loader))[0][:64].to(device)\n",
    "\n",
    "# create a grid of images\n",
    "img_grid = vutils.make_grid(sample_batch, padding=2, normalize=True)\n",
    "\n",
    "# convert to NumPy and transpose dimensions for matplotlib\n",
    "img_grid_np = np.transpose(img_grid.cpu().numpy(), (1, 2, 0))\n",
    "\n",
    "# plot the grid of images\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(img_grid_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch of training images\n",
    "sample_batch = next(iter(val_loader))[0][:64].to(device)\n",
    "\n",
    "# create a grid of images\n",
    "img_grid = vutils.make_grid(sample_batch, padding=2, normalize=True)\n",
    "\n",
    "# convert to NumPy and transpose dimensions for matplotlib\n",
    "img_grid_np = np.transpose(img_grid.cpu().numpy(), (1, 2, 0))\n",
    "\n",
    "# plot the grid of images\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Validation Images\")\n",
    "plt.imshow(img_grid_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup core training objects\n",
    "\n",
    "Look into available loss functions [here](https://pytorch.org/docs/stable/nn.html#loss-functions).\n",
    "\n",
    "Look into available optimizers [here](https://pytorch.org/docs/stable/optim.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationNetwork()\n",
    "model.to(device)\n",
    "\n",
    "# selecting cross entropy as the loss function for our classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# selecting stochastic gradient descent as our optimization algorithm\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training\n",
    "\n",
    "What is different here from the training we did for the MNIST CNN classifier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # training loop\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # get data\n",
    "        inputs = data.to(device)\n",
    "        labels = target.to(device)\n",
    "        \n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        predictions = model(inputs)\n",
    "        # compute the loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # update the parameters, i.e. weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # save statistics to plot later\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # validation loop\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # get data\n",
    "            inputs = data.to(device)\n",
    "            labels = target.to(device)\n",
    "            # forward pass, no backpropagation and optimisation\n",
    "            predictions = model(inputs)\n",
    "            # compute the loss\n",
    "            loss = criterion(predictions, labels)\n",
    "            # save statistics to plot later\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # normalise cumulative losses to dataset size\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # added cumulative losses to lists to plot later\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, train loss: {train_loss:.3f}, val loss: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot training vs validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Train vs validation loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.plot(val_losses,label=\"val\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cumulative loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/img_classifier.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks to do in-class and further explore at home\n",
    "\n",
    "**Task 1:** Create your own dataset with 2, 3, or more classes, based on one of the suggested approaches. It would be effective to have at least 1000 images/class. Create a folder for each one of your classes and save the respective images there. Then move all of the class folders in `./data/my_image_dataset`. Make sure you manually clean-up your data before training, to remove any irrelevant or destroyed images.\n",
    "\n",
    "**Task 2:** Run all the cells in this code to train a classifier on your custom dataset.\n",
    "\n",
    "**Task 3:** Add image transformations on the training dataset. Look in [here](https://pytorch.org/vision/stable/transforms.html) and [here](https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py) for references and examples. \n",
    "\n",
    "**Task 4:** Create a new notebook where you call the model that you just saved from this training and test it on some new unseen data. Look into the MNIST notebooks 01 and 02, as well as the PyTorch website, to figure out how you can call and use an already trained model.\n",
    "\n",
    "**Bonus Challenges:**\n",
    "\n",
    "**Bonus 1:** Look into the concept of Early Stopping. What is it? Could it be useful for our training? How? Attempt to implement it by adding the following lines of code after the training loop is completed:\n",
    "\n",
    "   `if val_loss < best_loss:`\n",
    "        \n",
    "        `best_loss = val_loss`\n",
    "        \n",
    "        `torch.save(model.state_dict(), 'best_img_classifier.pt')`\n",
    "\n",
    "For this to work, you will have to initialise best_loss with a high value before you enter the training loop.\n",
    "\n",
    "**Bonus 2:** In this example you are building your classifier from scratch, i.e. you decide yourself what the architecture of the network is and you train it from the very beginning. Could you explore a way for training your classifier based on a pre-trained model? There are many available pre-trained models in [the torchvision models library](https://pytorch.org/vision/stable/models.html), like [ResNet](https://arxiv.org/abs/1512.03385) which is trained on [imagenet dataset](https://www.image-net.org/). This approach will require a few changes and additions in your notebook. Attempt it if you are feeling adventurous!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to work in Google Colab with your notebooks and datasets, you need to mount your drive to the machine. Start the notebook with the commands below:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# change directory using the os module\n",
    "import os\n",
    "os.chdir('drive/My Drive/')\n",
    "os.listdir()                # shows the contents of the current dir\n",
    "# os.mkdir(\"my-colab-repo\") # creating a directory\n",
    "# os.chdir(\"my-colab-repo\") # moving to this directory\n",
    "# os.getcwd()               # printing the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmlap25my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
